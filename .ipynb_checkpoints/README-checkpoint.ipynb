{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Nanodegree Capstone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allstate Insurence Severity Detection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allstate insurence, the second largest personal lines insurer in the United States and the largest that is publicly held, approximatly 16 million households. For this challenge, Allstate has provided vast dataset on its insurence claims, several dozen key attributes, thorugh which data analysis could help uncover the underlying pattern in detecting the severeness of an insurance claim. Data is provided in the form of categorical, continues format. This challenge, is a very great problem to tackle with machine learning. The automation of reviweing insurance claims will improves productivity and efficiency which will inevitably lead to happier customers and overall satisfaction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The challenge requires the data scientists to best predict the label column, or 'loss' as indicated in the data provided. Since the dataset contains both categorical and continious data along with several dozen attributes, and several hundread rows of insurence claim instances, the final algorithm will have to take these constraints into consideraiton. And as such, I belive that a mix of decision tree, supervised regression algorithm will best be able to solve this challenge. For example as refrence to some of the publicly avialable best performing kernels in the challenge page on kaggle can show that XGBoost, MLP, and such perform the best. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge Roadmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Understanding the Dataset **\n",
    " * Data Shape \n",
    " * Skew \n",
    " * Mean, STD deviation, Max, etc. \n",
    " \n",
    "** Data Visualization **\n",
    " * Scatter Plots\n",
    " * Correlation\n",
    " * Density Plots\n",
    " \n",
    "** Data Processing ** \n",
    " * Transformation\n",
    " * One-Hot encoding\n",
    " * Train/Test Data preparation\n",
    " \n",
    "** Model Evalaution **\n",
    " * Algorithm implementations\n",
    " * Model Evaluations\n",
    " * Model Predicitons\n",
    " * Model Analysis\n",
    " \n",
    "** Appendix **\n",
    " * Conclusion\n",
    " * Personal Thoughts\n",
    " * Thanks and Appreciations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Highlights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Check the report.md for in depth analysis of the challenge and it's highlights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries and Dependencies used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    " * Sklearn\n",
    "    * metrics\n",
    "    * Linear Regression\n",
    "    * GradientBoosting\n",
    "    * DecisionTree\n",
    "    * SGD\n",
    "    * RandomForest\n",
    "    * MLP \n",
    " * Numpy\n",
    " * Pandas\n",
    " * Matplotlib\n",
    " * Seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Core Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "train.csv = train Data provided by Allstate Challenge. The original Shape of the data is in (188318, 131). This dataset also includes the 'loss' column by which we'll be completing the challenge.\n",
    "\n",
    "test.csv = test data provided by the challenge. The original shape of the data is in (125546, 130). This datset however does not include the 'loss' column. also train set does not include as munch insurance isntance claims as much as the train dataset. \n",
    "\n",
    "CapstoneProject.ipynb = This is the main notebook, it includes all the analysis, model building, and predicting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supplementary Refrences and  Link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Kaggle Challnege: https://www.kaggle.com/c/allstate-claims-severity\n",
    "Refrences: \n",
    "* metric: https://medium.com/human-in-a-machine-world/mae-and-rmse-which-metric-is-better-e60ac3bde13d, https://www.kaggle.com/c/allstate-claims-severity/discussion/24520#140255\n",
    "* Major thanks and appreiciation for the influence to: https://www.kaggle.com/sharmasanthosh/exploratory-study-on-ml-algorithms, https://www.kaggle.com/snmateen/simple-eda-feature-transformations, https://www.kaggle.com/laurae2/sneak-peak-at-the-data-1, https://www.kaggle.com/achalshah/allstate-feature-analysis-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
